{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collision 해결"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5X5 시야(FOV)를 가정\n",
    "\n",
    "구현 순서 (open, 2명)\n",
    "1. 두 명 이상의 에이전트가 서로의 시야에 들어온다\n",
    "2. 두 에이전트의 숫자를 비교하여 작은 쪽이 정지하게 한다\n",
    "3. 정지한 다른 에이전트를 장애물로 취급하고 큰 쪽이 navigate를 이어간다\n",
    "\n",
    "구현 순서 (bottleneck, 2명)\n",
    "1. 두 명 이상의 에이전트가 서로의 시야에 들어온다\n",
    "2. 두 에이전트의 숫자를 비교하여 작은 쪽이 반대 방향으로 돌아가게 한다\n",
    "3. 큰 쪽은 navigate를 이어간다\n",
    "4. 쭉 주위 환경을 관찰하여 작은 쪽이 더이상 비키지 않아도 될 때 end.\n",
    "\n",
    "한 달 동안 계속 해결해야 할 문제: 에이전트와 장애물이 복잡하게 섞인 상황에서 도대체 negotiator를 어떻게 설계할 것인지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from crewai import Agent, Task, Crew\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "from environment import Environment\n",
    "import configs\n",
    "import pickle\n",
    "\n",
    "#negotiator를 구성하기 위한 union find 알고리즘\n",
    "\n",
    "def find(parent, i):\n",
    "    if parent[i] == i:\n",
    "        return i\n",
    "    else:\n",
    "        return find(parent, parent[i])\n",
    "\n",
    "def union(parent, rank, x, y):\n",
    "    xroot = find(parent, x)\n",
    "    yroot = find(parent, y)\n",
    "\n",
    "    if xroot != yroot:\n",
    "        if rank[xroot] < rank[yroot]:\n",
    "            parent[xroot] = yroot\n",
    "        elif rank[xroot] > rank[yroot]:\n",
    "            parent[yroot] = xroot\n",
    "        else:\n",
    "            parent[yroot] = xroot\n",
    "            rank[xroot] += 1\n",
    "\n",
    "def merge_sets(lists):\n",
    "    element_to_index = {}\n",
    "    for i, subset in enumerate(lists):\n",
    "        for element in subset:\n",
    "            element_to_index[element] = i\n",
    "\n",
    "    parent = [i for i in range(len(lists))]\n",
    "    rank = [0] * len(lists)\n",
    "\n",
    "    for subset in lists:\n",
    "        first_element = subset[0]\n",
    "        for element in subset[1:]:\n",
    "            union(parent, rank, find(parent, element_to_index[first_element]), find(parent, element_to_index[element]))\n",
    "\n",
    "    new_sets = {}\n",
    "    for element in element_to_index:\n",
    "        root = find(parent, element_to_index[element])\n",
    "        if root not in new_sets:\n",
    "            new_sets[root] = set()\n",
    "        new_sets[root].add(element)\n",
    "\n",
    "    return [list(s) for s in new_sets.values()]\n",
    "\n",
    "\n",
    "directiondict = {\n",
    "    'Stay': 0, 'North': 1, 'South': 2, 'West': 3, 'East': 4, 'Stay.': 0, 'North.': 1, 'South.': 2, 'West.': 3, 'East.': 4 \n",
    "}\n",
    "\n",
    "num_agents = 2\n",
    "\n",
    "# Toy example 만들기(환경, 처음 위치, 목적지)\n",
    "toy = (np.array([[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]), np.array([[2, 0], [2, 4]]), np.array([[2, 4], [2, 0]]))\n",
    "\n",
    "env = Environment()\n",
    "env.load(toy[0], toy[1], toy[2])\n",
    "env.render()\n",
    "\n",
    "class PathFindingAgents():\n",
    "\tdef path_finder(self, agent_number):\n",
    "\t\treturn Agent(\n",
    "\t\t\trole='Path finder',\n",
    "\t\t\tgoal='Start at the start point and reach the end point without crashing into a wall.',\n",
    "\t\t\tbackstory=f\"\"\"You are a veteran adventurer with a great sense of direction.\n",
    "\t\t\tYou understand which direction you need to move to get from where you are to where you want to go.\n",
    "\t\t\tYour agent number is {agent_number}.\n",
    "\t\t\t\"\"\",\n",
    "\t\t\tverbose=True\n",
    "\t\t)\n",
    "\t\n",
    "# action에 stay 추가 필요.\n",
    "class PathFindingTasks():\n",
    "\tdef path_finding(self, agent, x, y, x_finish, y_finish, east, west, north, south, last_action):\n",
    "\t\treturn Task(\n",
    "  \tdescription=(f\"\"\"\n",
    "    Your current coordinates are ({x},{y}) and your destination is ({x_finish},{y_finish}).\n",
    "    East and west in the coordinates correspond to the x axis.\n",
    "    South and north in the coordinated correspond to the y axis.\n",
    "    You can only move east, west, south and north or stay.\n",
    "    So, your answer will be {{East}}, {{West}}, {{South}}, {{North}}, or {{Stay}}.\n",
    "    You can only make one move at a time.\n",
    "    {east}\n",
    "    {west}\n",
    "    {south}\n",
    "    {north}\n",
    "    Which direction do you move next?\n",
    "    {last_action}\n",
    "    Answer in one word only: {{DIRECTION or ACTION}}\n",
    "    \"\"\"),\n",
    "    expected_output='Direction or action',\n",
    "    agent=agent\n",
    "    )\n",
    "\n",
    "\n",
    "agents = PathFindingAgents()\n",
    "tasks = PathFindingTasks()\n",
    "\n",
    "agent0 = agents.path_finder(0)\n",
    "agent1 = agents.path_finder(1)\n",
    "\n",
    "agents_set = [agent0, agent1]\n",
    "\n",
    "# 작업 필요\n",
    "negotiator = Agent(\n",
    "  role='Negotiator',\n",
    "  goal=\"\"\"Determine whether the deadlocked agents would collide with each other if they took their original planned moves, and if so, stop all but the agent with the largest number.\"\"\",\n",
    "  backstory=\"\"\"You're a veteran overseer, and you've been called in to resolve the deadlock, as each agent is in the other's line of sight.\n",
    "  \"\"\",\n",
    "  verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#에이전트들의 지난번 액션들\n",
    "action_list = [[] for _ in range(num_agents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 16:45:40,728 - 26264 - __init__.py-__init__:518 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mConsidering my current position (0,2) and the destination (4,2), the best move would be to head in the direction which brings me closer to the destination. The x-coordinate needs to increase from 0 to 4, while the y-coordinate is already at the required position of 2. Therefore, the optimal direction to move next would be East.\n",
      "\n",
      "Final Answer: East.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mIn order to reach my destination from my current coordinates, I need to move towards the west as it will decrease the x-coordinate and bring me closer to my destination.\n",
      "\n",
      "Final Answer: West\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1 turn\n",
    "for n in range(1):\n",
    "\n",
    "  step = [0 for i in range(num_agents)]\n",
    "\n",
    "  FOV_agents = []\n",
    "  for i in range(num_agents):\n",
    "    if np.any(env.observe()[0][i][0][2:7, 2:7]):\n",
    "      non_zero_elements = env.observe()[0][i][0][2:7, 2:7][env.observe()[0][i][0][2:7, 2:7] != 0].tolist()\n",
    "      non_zero_elements = [element - 1 for element in non_zero_elements]\n",
    "      non_zero_elements.append(i)\n",
    "      FOV_agents.append(non_zero_elements)\n",
    "\n",
    "  negotiator_set = merge_sets(FOV_agents)\n",
    "  flattened_set = [item for sublist in negotiator_set for item in sublist]\n",
    "\n",
    "  for i in range(num_agents):\n",
    "\n",
    "    if i not in flattened_set:\n",
    "      \n",
    "      a_obs = env.observe()[0][i][1]\n",
    "      x = env.observe()[1][i][1]\n",
    "      y = 4-env.observe()[1][i][0]\n",
    "      x_finish = toy[2][i][1]\n",
    "      y_finish = 4-toy[2][i][0]\n",
    "\n",
    "      if a_obs[4][3] == 0:\n",
    "        west = \"\"\"To your west lies a path.\"\"\"\n",
    "      else:\n",
    "        west = \"\"\"Your west is blocked by a wall.\"\"\"\n",
    "\n",
    "      if a_obs[4][5] == 0:\n",
    "        east = \"\"\"To your east lies a path.\"\"\"\n",
    "      else:\n",
    "        east = \"\"\"Your east is blocked by a wall.\"\"\"\n",
    "\n",
    "      if a_obs[5][4] == 0:\n",
    "        south = \"\"\"To your south lies a path.\"\"\"\n",
    "      else:\n",
    "        south = \"\"\"Your south is blocked by a wall.\"\"\"\n",
    "\n",
    "      if a_obs[3][4] == 0:\n",
    "        north = \"\"\"To your north lies a path.\"\"\"\n",
    "      else:\n",
    "        north = \"\"\"Your north is blocked by a wall.\"\"\"\n",
    "\n",
    "      if len(action_list[i]) == 0:\n",
    "        last_action = \"\"\"\"\"\"\n",
    "      elif action_list[i][-1] in ['West', 'West.']:\n",
    "        last_action = f\"\"\"You came from east.\"\"\"\n",
    "      elif action_list[i][-1] in ['East', 'East.']:\n",
    "        last_action = f\"\"\"You came from west.\"\"\"\n",
    "      elif action_list[i][-1] in ['South', 'South.']:\n",
    "        last_action = f\"\"\"You came from north.\"\"\"\n",
    "      elif action_list[i][-1] in ['North', 'North.']:\n",
    "        last_action = f\"\"\"You came from south.\"\"\"\n",
    "      elif action_list[i][-1] in ['Stay', 'Stay.']:\n",
    "        last_action = f\"\"\"You paused once for another agent.\"\"\"\n",
    "      else:\n",
    "        last_action = \"\"\"\"\"\"\n",
    "\n",
    "      navigation = tasks.path_finding(agents_set[i], x, y, x_finish, y_finish, east, west, north, south, last_action)\n",
    "\n",
    "      crew = Crew(\n",
    "        agents=[agents_set[i]],\n",
    "        tasks=[navigation],\n",
    "        verbose=0,\n",
    "      )\n",
    "\n",
    "      result = crew.kickoff()\n",
    "\n",
    "      action_list[i].append(result)\n",
    "    \n",
    "      step[i] = directiondict[result]\n",
    "\n",
    "  \n",
    "  #여기에 negotiate할 에이전트들을 계획.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  env.step(step)\n",
    "  env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### negotiate 실험(잘 되면 위 코드로 넣기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOV_agents = []\n",
    "for i in range(num_agents):\n",
    "  if np.any(env.observe()[0][i][0][2:7, 2:7]):\n",
    "    non_zero_elements = env.observe()[0][i][0][2:7, 2:7][env.observe()[0][i][0][2:7, 2:7] != 0].tolist()\n",
    "    non_zero_elements = [element - 1 for element in non_zero_elements]\n",
    "    non_zero_elements.append(i)\n",
    "    FOV_agents.append(non_zero_elements)\n",
    "\n",
    "negotiator_set = merge_sets(FOV_agents)\n",
    "flattened_set = [item for sublist in negotiator_set for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "navigation_set = []\n",
    "\n",
    "for i in negotiator_set[0]:\n",
    "    \n",
    "    a_obs = env.observe()[0][i][1]\n",
    "    x = env.observe()[1][i][1]\n",
    "    y = 4-env.observe()[1][i][0]\n",
    "    x_finish = toy[2][i][1]\n",
    "    y_finish = 4-toy[2][i][0]\n",
    "\n",
    "    if a_obs[4][3] == 0:\n",
    "        west = \"\"\"To your west lies a path.\"\"\"\n",
    "    else:\n",
    "        west = \"\"\"Your west is blocked by a wall.\"\"\"\n",
    "\n",
    "    if a_obs[4][5] == 0:\n",
    "        east = \"\"\"To your east lies a path.\"\"\"\n",
    "    else:\n",
    "        east = \"\"\"Your east is blocked by a wall.\"\"\"\n",
    "\n",
    "    if a_obs[5][4] == 0:\n",
    "        south = \"\"\"To your south lies a path.\"\"\"\n",
    "    else:\n",
    "        south = \"\"\"Your south is blocked by a wall.\"\"\"\n",
    "\n",
    "    if a_obs[3][4] == 0:\n",
    "        north = \"\"\"To your north lies a path.\"\"\"\n",
    "    else:\n",
    "        north = \"\"\"Your north is blocked by a wall.\"\"\"\n",
    "\n",
    "    if len(action_list[i]) == 0:\n",
    "        last_action = \"\"\"\"\"\"\n",
    "    elif action_list[i][-1] in ['West', 'West.']:\n",
    "        last_action = f\"\"\"You came from east.\"\"\"\n",
    "    elif action_list[i][-1] in ['East', 'East.']:\n",
    "        last_action = f\"\"\"You came from west.\"\"\"\n",
    "    elif action_list[i][-1] in ['South', 'South.']:\n",
    "        last_action = f\"\"\"You came from north.\"\"\"\n",
    "    elif action_list[i][-1] in ['North', 'North.']:\n",
    "        last_action = f\"\"\"You came from south.\"\"\"\n",
    "    elif action_list[i][-1] in ['Stay', 'Stay.']:\n",
    "        last_action = f\"\"\"You paused once for another agent.\"\"\"\n",
    "    else:\n",
    "        last_action = \"\"\"\"\"\"\n",
    "\n",
    "    navigation_set.append(tasks.path_finding(agents_set[i], x, y, x_finish, y_finish, east, west, north, south, last_action))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 16:45:56,835 - 26264 - __init__.py-__init__:518 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mSince I am at (1,2) and my destination is at (4,2), and since the x-coordinates increase as I move east, the most direct path would be to move east. The task states that there is a path to the east, so I can move in that direction without crashing into a wall. \n",
      "\n",
      "Action: \n",
      "None\n",
      "\n",
      "Action Input: \n",
      "None\n",
      "\u001b[0m\u001b[91m \n",
      "\n",
      "Action 'None' don't exist, these are the only available Actions:\n",
      " Delegate work to co-worker: Delegate work to co-worker(task: str, context: str, coworker: Optional[str] = None, **kwargs) - Delegate a specific task to one of the following co-workers: [Path finder, Negotiator]\n",
      "The input to this tool should be the co-worker, the task you want them to do, and ALL necessary context to execute the task, they know nothing about the task, so share absolute everything you know, don't reference things but instead explain them.\n",
      "Ask question to co-worker: Ask question to co-worker(question: str, context: str, coworker: Optional[str] = None, **kwargs) - Ask a specific question to one of the following co-workers: [Path finder, Negotiator]\n",
      "The input to this tool should be the co-worker, the question you have for them, and ALL necessary context to ask the question properly, they know nothing about the question, so share absolute everything you know, don't reference things but instead explain them.\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: I now can give a great answer\n",
      "Final Answer: East\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mSince I'm currently at coordinates (3,2) and my destination is at (0,2), I need to move towards the west to decrease my x-coordinate. I know that I came from the east and there's a path to the west, so I should move west.\n",
      "\n",
      "Action:  \n",
      "None\n",
      "\n",
      "Action Input: \n",
      "None\n",
      "\u001b[0m\u001b[91m \n",
      "\n",
      "Action 'None' don't exist, these are the only available Actions:\n",
      " Delegate work to co-worker: Delegate work to co-worker(task: str, context: str, coworker: Optional[str] = None, **kwargs) - Delegate a specific task to one of the following co-workers: [Path finder, Negotiator]\n",
      "The input to this tool should be the co-worker, the task you want them to do, and ALL necessary context to execute the task, they know nothing about the task, so share absolute everything you know, don't reference things but instead explain them.\n",
      "Ask question to co-worker: Ask question to co-worker(question: str, context: str, coworker: Optional[str] = None, **kwargs) - Ask a specific question to one of the following co-workers: [Path finder, Negotiator]\n",
      "The input to this tool should be the co-worker, the question you have for them, and ALL necessary context to ask the question properly, they know nothing about the question, so share absolute everything you know, don't reference things but instead explain them.\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
      "Final Answer: West\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mFirst, I need to determine the planned moves of the agents. I can do this by asking my co-worker, Path finder, about the possible outcomes of the planned moves. \n",
      "\n",
      "Action: \n",
      "Ask question to co-worker\n",
      "\n",
      "Action Input: \n",
      "{\n",
      "  \"question\": \"What are the outcomes of the planned moves of the agents?\",\n",
      "  \"context\": \"The agents are in deadlock and we need to avoid a collision if they proceed with their planned moves. I need the potential outcomes of these planned moves to understand whether they will collide or not.\",\n",
      "  \"coworker\": \"Path finder\"\n",
      "}\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo provide the most complete answer to this task, I need to analyze the current positions of the agents and their planned moves, considering the possible scenarios and outcomes. \n",
      "\n",
      "Final Answer: \n",
      "The outcomes of the planned moves of the agents depends largely on their current positions, their directions, and the environment they are operating in. If the agents are in deadlock, as you mentioned, it suggests that they are stuck in a situation where they are blocking each other's paths and any move could potentially lead to a collision. Here are few outcomes based on the planned moves:\n",
      "\n",
      "1. If the agents carry on with their planned moves without considering the deadlock, they could potentially collide with each other. This is the worst-case scenario.\n",
      "\n",
      "2. If the agents have the ability to foresee the deadlock and adjust their paths accordingly, they might be able to avoid the collision. This would require real-time decision-making capabilities and possibly advanced sensors to detect and avoid each other.\n",
      "\n",
      "3. If the agents are programmed to stop when they detect a potential collision, they might just remain in deadlock, unable to proceed further. This could lead to a standstill situation where no progress is made.\n",
      "\n",
      "4. If the agents are able to communicate with each other or with a central system, they could potentially negotiate a new path and avoid the collision. This would require advanced communication capabilities.\n",
      "\n",
      "These are the potential outcomes based on the planned moves of the agents. To give a more accurate prediction, I would need more specific details about the agents' current positions, their planned moves, their capabilities, and the environment they are operating in.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[95m \n",
      "\n",
      "The outcomes of the planned moves of the agents depends largely on their current positions, their directions, and the environment they are operating in. If the agents are in deadlock, as you mentioned, it suggests that they are stuck in a situation where they are blocking each other's paths and any move could potentially lead to a collision. Here are few outcomes based on the planned moves:\n",
      "\n",
      "1. If the agents carry on with their planned moves without considering the deadlock, they could potentially collide with each other. This is the worst-case scenario.\n",
      "\n",
      "2. If the agents have the ability to foresee the deadlock and adjust their paths accordingly, they might be able to avoid the collision. This would require real-time decision-making capabilities and possibly advanced sensors to detect and avoid each other.\n",
      "\n",
      "3. If the agents are programmed to stop when they detect a potential collision, they might just remain in deadlock, unable to proceed further. This could lead to a standstill situation where no progress is made.\n",
      "\n",
      "4. If the agents are able to communicate with each other or with a central system, they could potentially negotiate a new path and avoid the collision. This would require advanced communication capabilities.\n",
      "\n",
      "These are the potential outcomes based on the planned moves of the agents. To give a more accurate prediction, I would need more specific details about the agents' current positions, their planned moves, their capabilities, and the environment they are operating in.\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "I received a detailed response from my coworker, but it is clear that I need more specific information to answer the question accurately. I will delegate the task of gathering this information to my coworker, Path finder. \n",
      "\n",
      "Action: \n",
      "Delegate work to co-worker\n",
      "\n",
      "Action Input: \n",
      "{\n",
      "  \"task\": \"Gather specific details about the agents' current positions, their planned moves, their capabilities, and the environment they are operating in\",\n",
      "  \"context\": \"We need these details to accurately predict whether the agents will collide if they proceed with their planned moves. The agents are currently in deadlock.\",\n",
      "  \"coworker\": \"Path finder\"\n",
      "}\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mIn order to provide the most accurate prediction, I need to gather specific data about the agents' current positions, their planned moves, their capabilities, and the environment they are operating in.\n",
      "\n",
      "Final Answer:\n",
      "To gather the required details, we need to follow these steps:\n",
      "\n",
      "1. Current Positions: We need to map out the exact coordinates of where the agents are currently located. This will give us a clear picture of their starting points and how close they are to each other.\n",
      "\n",
      "2. Planned Moves: We need to understand their planned moves. This includes their intended direction, the number of steps they plan to take, and their speed. This will help us calculate if and when they might collide.\n",
      "\n",
      "3. Capabilities: We need to know the agents' capabilities. This includes things like their maximum speed, their ability to change direction, and their ability to stop or slow down. This will help us understand if they have the ability to avoid a collision once they realize they are on a collision course.\n",
      "\n",
      "4. Environment: We need to map out the environment they are operating in. This includes any obstacles, the size and shape of the operating area, and any other environmental factors that could affect their movement.\n",
      "\n",
      "By gathering and analyzing this information, we can accurately predict if the agents will collide if they proceed with their planned moves.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[95m \n",
      "\n",
      "To gather the required details, we need to follow these steps:\n",
      "\n",
      "1. Current Positions: We need to map out the exact coordinates of where the agents are currently located. This will give us a clear picture of their starting points and how close they are to each other.\n",
      "\n",
      "2. Planned Moves: We need to understand their planned moves. This includes their intended direction, the number of steps they plan to take, and their speed. This will help us calculate if and when they might collide.\n",
      "\n",
      "3. Capabilities: We need to know the agents' capabilities. This includes things like their maximum speed, their ability to change direction, and their ability to stop or slow down. This will help us understand if they have the ability to avoid a collision once they realize they are on a collision course.\n",
      "\n",
      "4. Environment: We need to map out the environment they are operating in. This includes any obstacles, the size and shape of the operating area, and any other environmental factors that could affect their movement.\n",
      "\n",
      "By gathering and analyzing this information, we can accurately predict if the agents will collide if they proceed with their planned moves.\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "My coworker has provided a detailed plan on how to gather the required information. However, I still do not have the necessary information to determine whether the agents will collide. I need to ask my coworker to execute this plan and provide the gathered information.\n",
      "\n",
      "Action: \n",
      "Delegate work to co-worker\n",
      "\n",
      "Action Input: \n",
      "{\n",
      "  \"task\": \"Execute the plan and provide the gathered information\",\n",
      "  \"context\": \"We need this information to predict whether the agents will collide if they proceed with their planned moves. Please follow the steps you outlined: map out the agents' current positions and their planned moves, understand their capabilities, and map out the environment they are operating in.\",\n",
      "  \"coworker\": \"Path finder\"\n",
      "}\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo provide the most accurate prediction, I will need to follow the steps as outlined. First, I will map out the agents' current positions and their planned moves. For each agent, I will need to know their current location, their intended destination, and the path they plan to take to get there. I will also need to understand their capabilities, such as their speed, range, and ability to change direction quickly. \n",
      "\n",
      "Next, I will map out the environment they are operating in. This will include the layout of the terrain, any obstacles or barriers that could impede movement, and any other relevant factors. Once I have gathered all this information, I can use it to predict whether the agents will collide if they proceed with their planned moves.\n",
      "\n",
      "Final Answer: According to the data gathered, agents' current positions, their planned movements, their capabilities, and the environment they are operating in, I can now predict whether a collision will occur or not. If the agents follow their planned path without considering other agents' movements and the environment's constraints, there is a high probability of collision. However, with proper coordination and awareness of the environment, the agents can avoid a collision.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[95m \n",
      "\n",
      "According to the data gathered, agents' current positions, their planned movements, their capabilities, and the environment they are operating in, I can now predict whether a collision will occur or not. If the agents follow their planned path without considering other agents' movements and the environment's constraints, there is a high probability of collision. However, with proper coordination and awareness of the environment, the agents can avoid a collision.\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "The coworker has gathered the necessary information and provided an analysis. According to this analysis, there is a high probability of collision if the agents proceed with their planned moves without considering other agents' movements and the environment's constraints. However, the agents can avoid a collision with proper coordination and awareness of the environment. As my task is to stop all but the agent with the largest number in case of a collision, I will have to ask my coworker to identify this agent.\n",
      "\n",
      "Action: \n",
      "Ask question to co-worker\n",
      "\n",
      "Action Input: \n",
      "{\n",
      "  \"question\": \"Which agent has the largest number?\",\n",
      "  \"context\": \"In case of a collision, we need to stop all but the agent with the largest number. Please identify this agent based on the information you have gathered.\",\n",
      "  \"coworker\": \"Path finder\"\n",
      "}\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAs a Pathfinder, I usually deal with direction and navigation tasks, not identifying agent numbers. However, I can tell you that the agent with the largest number would be the one with the highest numerical value assigned to them. Without specific data on the available agent numbers, I can't identify which agent has the largest number.\n",
      "\n",
      "Final Answer: \n",
      "I'm sorry but I am unable to identify which agent has the largest number without specific data on the available agent numbers.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[95m \n",
      "\n",
      "I'm sorry but I am unable to identify which agent has the largest number without specific data on the available agent numbers.\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3mThought: \n",
      "My coworker is unable to identify the agent with the largest number without specific data. Since I don't have this data, I will assume that if a collision is predicted, all agents should be stopped to prevent it. \n",
      "\n",
      "Final Answer: \n",
      "If the agents proceed with their planned moves without considering other agents' movements and the environment's constraints, there is a high probability of a collision. Therefore, to prevent a collision, all agents should be stopped.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "negotiate = Task(\n",
    "  \tdescription=(f\"\"\"\n",
    "    Determine whether the deadlocked agents would collide with each other if they took their original planned moves, and if so, stop all but the agent with the largest number.\n",
    "    The planned moves of each agent represent the previous outcomes.\n",
    "    \"\"\"),\n",
    "    expected_output='Direction of two agents',\n",
    "    agent=negotiator\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[agents_set[0], agents_set[1], negotiator],\n",
    "    tasks=[navigation_set[0], navigation_set[1], negotiate],\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "result = crew.kickoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negotiator_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Agent(role=Path finder, goal=Start at the start point and reach the end point without crashing into a wall., backstory=You are a veteran adventurer with a great sense of direction.\n",
       " \t\t\tYou understand which direction you need to move to get from where you are to where you want to go.\n",
       " \t\t\tYour agent number is 0.\n",
       " \t\t\t),\n",
       " Agent(role=Path finder, goal=Start at the start point and reach the end point without crashing into a wall., backstory=You are a veteran adventurer with a great sense of direction.\n",
       " \t\t\tYou understand which direction you need to move to get from where you are to where you want to go.\n",
       " \t\t\tYour agent number is 1.\n",
       " \t\t\t)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "[agents_set[i] for i in negotiator_set[0] + negotiator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
